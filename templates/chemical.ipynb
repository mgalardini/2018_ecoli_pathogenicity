{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = 20\n",
    "strains = 'https://evocellnet.github.io/ecoref/data/strains.tsv'\n",
    "phenotypes = 'https://evocellnet.github.io/ecoref/data/phenotypic_data.tsv'\n",
    "pathogenicity = '../data/phenotypes/phenotypes.tsv'\n",
    "gdir = '../data/genomes/'\n",
    "filtered = '../out/associations/summary_cont_lmm_kmer.tsv'\n",
    "rtab = '../out/roary/gene_presence_absence.Rtab'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = int(cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting imports\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from adjustText import adjust_text\n",
    "\n",
    "sns.set_style('white')\n",
    "\n",
    "plt.rc('font', size=11)\n",
    "plt.rc('xtick', labelsize=11)\n",
    "plt.rc('ytick', labelsize=11)\n",
    "plt.rc('axes', labelsize=12, titlesize=12)\n",
    "plt.rc('legend', fontsize=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match(x, y, c,\n",
    "          xcolumn='s-scores',\n",
    "          ycolumn='killed'):\n",
    "    j = x.loc[c, xcolumn]\n",
    "    k = y.loc[j.index, ycolumn]\n",
    "    idx = j.index.intersection(k.index)\n",
    "    if len(idx) == 0:\n",
    "        return np.nan, np.nan\n",
    "    j = j.loc[idx]\n",
    "    k = k.loc[idx]\n",
    "    return j, k\n",
    "\n",
    "def correlate(x, y, c,\n",
    "              method='pearson',\n",
    "              xcolumn='s-scores',\n",
    "              ycolumn='killed'):\n",
    "    j, k = match(x, y, c, xcolumn, ycolumn)\n",
    "    if method == 'pearson':\n",
    "        return stats.pearsonr(j, k)\n",
    "    else:\n",
    "        return stats.spearmanr(j, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pd.read_table(filtered,\n",
    "                  index_col=0)\n",
    "f = f[f['specific_hits'] > 0]\n",
    "r = pd.read_table(rtab, index_col=0)\n",
    "r = r.loc[f.index].copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpi = r.sum()\n",
    "hpi.name = 'hpi'\n",
    "hpi = hpi.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = {'IAI29',\n",
    "           'IAI64',\n",
    "           'NILS80'}\n",
    "genomes = {x.split('.')[0]\n",
    "           for x in os.listdir(gdir)\n",
    "           if x.endswith('.fasta')} - exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.read_table(strains, index_col=1)\n",
    "s.index = [x.replace(' ', '')\n",
    "           if x.startswith('NILS')\n",
    "           else x\n",
    "           for x in s.index]\n",
    "s = s.loc[[k for k,v in s.T.iteritems()\n",
    "           if k in genomes\n",
    "           and v.values[0] != 'NT12008']][['Strain Identifier', 'Full Strain Name After Genome Analysis']].dropna()\n",
    "s = s['Strain Identifier']\n",
    "s = s.reset_index().set_index(\n",
    "    'Strain Identifier'\n",
    "    ).drop('NT12008').reset_index().set_index(\n",
    "    'index')['Strain Identifier']\n",
    "d = {v: k\n",
    "     for k, v in s.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pd.read_table(phenotypes).set_index('strain')\n",
    "p.index = [d.get(x, x)\n",
    "           for x in p.index]\n",
    "p.index.name = 'strain'\n",
    "p = p.reset_index().set_index(['strain', 'condition'])\n",
    "p = p.loc[s.index]\n",
    "p = p.reset_index().set_index(['condition', 'strain'])\n",
    "p = p.sort_index()\n",
    "p['signed-qvalue'] = [np.sign(x) * -np.log10(y)\n",
    "                      for x, y, z in p.values]\n",
    "# idx = p.groupby('condition')['growth-defect-phenotype'\n",
    "#         ].sum()[p.groupby('condition')[\n",
    "#       'growth-defect-phenotype'].sum() > 0].index\n",
    "# p = p.loc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = pd.read_table(pathogenicity,\n",
    "                  index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for c in {x[0] for x in p.index}:\n",
    "    r, pval = correlate(p, k, c)\n",
    "    res.append((c, 'pearson', 's-score', r, pval))\n",
    "    r, pval = correlate(p, k, c, method='spearman')\n",
    "    res.append((c, 'spearman', 's-score', r, pval))\n",
    "    r, pval = correlate(p, k, c, xcolumn='signed-qvalue')\n",
    "    res.append((c, 'pearson', 'signed-qvalue', r, pval))\n",
    "    r, pval = correlate(p, k, c, method='spearman', xcolumn='signed-qvalue')\n",
    "    res.append((c, 'spearman', 'signed-qvalue', r, pval))\n",
    "    r, pval = correlate(p, hpi, c, ycolumn='hpi')\n",
    "    res.append((c, 'pearson', 's-score.hpi', r, pval))\n",
    "    r, pval = correlate(p, hpi, c, method='spearman', ycolumn='hpi')\n",
    "    res.append((c, 'spearman', 's-score.hpi', r, pval))\n",
    "    r, pval = correlate(p, hpi, c, xcolumn='signed-qvalue', ycolumn='hpi')\n",
    "    res.append((c, 'pearson', 'signed-qvalue.hpi', r, pval))\n",
    "    r, pval = correlate(p, hpi, c, method='spearman', xcolumn='signed-qvalue', ycolumn='hpi')\n",
    "    res.append((c, 'spearman', 'signed-qvalue.hpi', r, pval))\n",
    "r = pd.DataFrame(res,\n",
    "                 columns=['condition',\n",
    "                          'method',\n",
    "                          'column',\n",
    "                          'r',\n",
    "                          'p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "plt.subplot(121)\n",
    "\n",
    "r1 = r[(r['method'] == 'pearson') &\n",
    "       (r['column'] == 's-score')].copy(deep=True)\n",
    "r1 = r1.set_index('condition')\n",
    "\n",
    "plt.scatter(r1['r'],\n",
    "            -np.log10(r1['p']),\n",
    "            color='k',\n",
    "            marker='o',\n",
    "            alpha=0.5)\n",
    "\n",
    "texts = []\n",
    "for t, v in r1[-np.log10(r1['p']) > 4.5].iterrows():\n",
    "    texts.append(plt.text(v['r'],\n",
    "                          -np.log10(v['p']),\n",
    "                          t,\n",
    "                          ha='center',\n",
    "                          va='center'))\n",
    "adjust_text(texts,\n",
    "            arrowprops=dict(arrowstyle='->', color='k'),\n",
    "            force_points=2)\n",
    "\n",
    "plt.title('s-scores Vs. pathogenicity')\n",
    "\n",
    "plt.ylim(-0.5, 9)\n",
    "\n",
    "plt.xlabel('pearson\\'s $r$')\n",
    "plt.ylabel('$-log_{10}(pvalue)$')\n",
    "\n",
    "plt.subplot(122)\n",
    "\n",
    "r1 = r[(r['method'] == 'pearson') &\n",
    "       (r['column'] == 's-score.hpi')].copy(deep=True)\n",
    "r1 = r1.set_index('condition')\n",
    "\n",
    "plt.scatter(r1['r'],\n",
    "            -np.log10(r1['p']),\n",
    "            color='k',\n",
    "            marker='o',\n",
    "            alpha=0.5)\n",
    "\n",
    "texts = []\n",
    "for t, v in r1[-np.log10(r1['p']) > 4.5].iterrows():\n",
    "    texts.append(plt.text(v['r'],\n",
    "                          -np.log10(v['p']),\n",
    "                          t,\n",
    "                          ha='center',\n",
    "                          va='center'))\n",
    "adjust_text(texts,\n",
    "            arrowprops=dict(arrowstyle='->', color='k'),\n",
    "            force_points=2)\n",
    "\n",
    "plt.title('s-scores Vs. HPI island')\n",
    "\n",
    "plt.ylim(-0.5, 9)\n",
    "\n",
    "plt.xlabel('pearson\\'s $r$')\n",
    "plt.ylabel('$-log_{10}(pvalue)$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "plt.subplot(121)\n",
    "\n",
    "r1 = r[(r['method'] == 'spearman') &\n",
    "       (r['column'] == 'signed-qvalue')].copy(deep=True)\n",
    "r1 = r1.set_index('condition')\n",
    "\n",
    "plt.scatter(r1['r'],\n",
    "            -np.log10(r1['p']),\n",
    "            color='k',\n",
    "            marker='o',\n",
    "            alpha=0.5)\n",
    "\n",
    "texts = []\n",
    "for t, v in r1[-np.log10(r1['p']) > 4.5].iterrows():\n",
    "    texts.append(plt.text(v['r'],\n",
    "                          -np.log10(v['p']),\n",
    "                          t,\n",
    "                          ha='center',\n",
    "                          va='center'))\n",
    "adjust_text(texts,\n",
    "            arrowprops=dict(arrowstyle='->', color='k'),\n",
    "            force_points=2)\n",
    "\n",
    "plt.title('signed-qvalue Vs. pathogenicity')\n",
    "\n",
    "plt.ylim(-0.5, 9.5)\n",
    "\n",
    "plt.xlabel('spearman\\'s $r$')\n",
    "plt.ylabel('$-log_{10}(pvalue)$')\n",
    "\n",
    "plt.subplot(122)\n",
    "\n",
    "r1 = r[(r['method'] == 'spearman') &\n",
    "       (r['column'] == 'signed-qvalue.hpi')].copy(deep=True)\n",
    "r1 = r1.set_index('condition')\n",
    "\n",
    "plt.scatter(r1['r'],\n",
    "            -np.log10(r1['p']),\n",
    "            color='k',\n",
    "            marker='o',\n",
    "            alpha=0.5)\n",
    "\n",
    "texts = []\n",
    "for t, v in r1[-np.log10(r1['p']) > 4.5].iterrows():\n",
    "    texts.append(plt.text(v['r'],\n",
    "                          -np.log10(v['p']),\n",
    "                          t,\n",
    "                          ha='center',\n",
    "                          va='center'))\n",
    "adjust_text(texts,\n",
    "            arrowprops=dict(arrowstyle='->', color='k'),\n",
    "            force_points=2)\n",
    "\n",
    "plt.title('signed-qvalue Vs. HPI island')\n",
    "\n",
    "plt.ylim(-0.5, 9.5)\n",
    "\n",
    "plt.xlabel('spearman\\'s $r$')\n",
    "plt.ylabel('$-log_{10}(pvalue)$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rndmfrst(x, y, xcolumn='s-scores'):\n",
    "    c = x[xcolumn].unstack().dropna().T\n",
    "    c['mouse'] = y.loc[c.index, 'phenotype']\n",
    "    \n",
    "    df = c[sorted(set(c.columns) - {'mouse'})]\n",
    "    target = c['mouse']\n",
    "    \n",
    "    cv = model_selection.StratifiedShuffleSplit(n_splits=1,\n",
    "                                                test_size=0.33,\n",
    "                                                random_state=np.random.RandomState(42))\n",
    "    train_idx, test_idx = next(cv.split(df, target))\n",
    "    \n",
    "    df_train, target_train = df.iloc[train_idx], target[train_idx]\n",
    "    df_test, target_test = df.iloc[test_idx], target[test_idx]\n",
    "    \n",
    "    param_grid = {'n_estimators': [int(x) for x in np.logspace(1, 3, 6)],\n",
    "                  'max_features': range(int(np.sqrt(df.shape[1])), int(df.shape[1] *0.7), 5)}\n",
    "\n",
    "    clf = RandomForestClassifier(random_state=np.random.RandomState(42))\n",
    "    grid_search = model_selection.GridSearchCV(clf,\n",
    "                                               param_grid=param_grid,\n",
    "                                               cv=model_selection.StratifiedShuffleSplit(n_splits=10,\n",
    "                                                              test_size=0.33,\n",
    "                                                              random_state=np.random.RandomState(42)),\n",
    "                                               scoring='f1',\n",
    "                                               n_jobs=cores)\n",
    "    grid_search.fit(df_train, target_train)\n",
    "    \n",
    "    clf = RandomForestClassifier(n_estimators=grid_search.best_params_['n_estimators'],\n",
    "                                 max_features=grid_search.best_params_['max_features'],\n",
    "                                 random_state=np.random.RandomState(42))\n",
    "    clf.fit(df_train, target_train)\n",
    "    predict_test = pd.Series(clf.predict(df_test),\n",
    "                             index=target_test.index,\n",
    "                             name='prediction')\n",
    "    combined = target_test.to_frame().join(predict_test.to_frame())\n",
    "    print(metrics.f1_score(combined['mouse'],\n",
    "                           combined['prediction']),\n",
    "          grid_search.best_score_)\n",
    "    \n",
    "    plt.figure(figsize=(7, 3.5))\n",
    "\n",
    "    plt.subplot(121)\n",
    "\n",
    "    fpr, tpr, _ = metrics.roc_curve(combined['mouse'], clf.predict_proba(df_test)[:, 1])\n",
    "\n",
    "    plt.plot(fpr, tpr,\n",
    "             'k-',\n",
    "             label='AUC %.2f' % metrics.auc(fpr, tpr))\n",
    "    plt.plot([0, 1],\n",
    "             [0, 1],\n",
    "             '--',\n",
    "             color=sns.xkcd_rgb['grey'])\n",
    "\n",
    "    plt.legend(frameon=True)\n",
    "\n",
    "    plt.xlabel('fpr'),\n",
    "    plt.ylabel('tpr')\n",
    "\n",
    "    plt.subplot(122)\n",
    "\n",
    "    prec, rec, _ = metrics.precision_recall_curve(combined['mouse'], clf.predict_proba(df_test)[:, 1])\n",
    "\n",
    "    plt.plot(rec, prec,\n",
    "             'k-',)\n",
    "    \n",
    "    plt.axhline(target_test[target_test == 1].shape[0] / target_test.shape[0],\n",
    "                color=sns.xkcd_rgb['grey'],\n",
    "                ls='dashed')\n",
    "\n",
    "    plt.xlabel('recall'),\n",
    "    plt.ylabel('precision')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = rndmfrst(p, k, 's-scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = rndmfrst(p, k, 'signed-qvalue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = pd.Series(clf1.feature_importances_,\n",
    "               p['s-scores'].unstack().dropna().T.columns)\n",
    "r1 = r[(r['method'] == 'pearson') &\n",
    "       (r['column'] == 's-score')].copy(deep=True)\n",
    "r1['fi'] = [np.nan for x in range(r1.shape[0])]\n",
    "r1 = r1.set_index('condition')\n",
    "r1.loc[fi.index,\n",
    "       'fi'] = fi.values\n",
    "r1 = r1.dropna()\n",
    "\n",
    "plt.figure(figsize=(6, 7))\n",
    "\n",
    "plt.scatter(r1['r'],\n",
    "            -np.log10(r1['p']),\n",
    "            s=r1['fi']*2000,\n",
    "            color='k',\n",
    "            marker='o',\n",
    "            alpha=0.5)\n",
    "\n",
    "texts = []\n",
    "for t, v in r1[-np.log10(r1['p']) > 2].iterrows():\n",
    "    texts.append(plt.text(v['r'],\n",
    "                          -np.log10(v['p']),\n",
    "                          t,\n",
    "                          ha='center',\n",
    "                          va='center'))\n",
    "adjust_text(texts,\n",
    "            arrowprops=dict(arrowstyle='->', color='k'),\n",
    "            force_points=2)\n",
    "\n",
    "plt.xlabel('pearson\\'s $r$')\n",
    "plt.ylabel('$-log_{10}(pvalue)$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = pd.Series(clf1.feature_importances_,\n",
    "               p['s-scores'].unstack().dropna().T.columns)\n",
    "r1 = r[(r['method'] == 'spearman') &\n",
    "       (r['column'] == 's-score')].copy(deep=True)\n",
    "r1['fi'] = [np.nan for x in range(r1.shape[0])]\n",
    "r1 = r1.set_index('condition')\n",
    "r1.loc[fi.index,\n",
    "       'fi'] = fi.values\n",
    "r1 = r1.dropna()\n",
    "\n",
    "plt.figure(figsize=(6, 7))\n",
    "\n",
    "plt.scatter(r1['r'],\n",
    "            -np.log10(r1['p']),\n",
    "            s=r1['fi']*2000,\n",
    "            color='k',\n",
    "            marker='o',\n",
    "            alpha=0.5)\n",
    "\n",
    "texts = []\n",
    "for t, v in r1[-np.log10(r1['p']) > 2].iterrows():\n",
    "    texts.append(plt.text(v['r'],\n",
    "                          -np.log10(v['p']),\n",
    "                          t,\n",
    "                          ha='center',\n",
    "                          va='center'))\n",
    "adjust_text(texts,\n",
    "            arrowprops=dict(arrowstyle='->', color='k'),\n",
    "            force_points=2)\n",
    "\n",
    "plt.xlabel('spearman\\'s $r$')\n",
    "plt.ylabel('$-log_{10}(pvalue)$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = pd.Series(clf2.feature_importances_,\n",
    "               p['s-scores'].unstack().dropna().T.columns)\n",
    "r1 = r[(r['method'] == 'pearson') &\n",
    "       (r['column'] == 'signed-qvalue')].copy(deep=True)\n",
    "r1['fi'] = [np.nan for x in range(r1.shape[0])]\n",
    "r1 = r1.set_index('condition')\n",
    "r1.loc[fi.index,\n",
    "       'fi'] = fi.values\n",
    "r1 = r1.dropna()\n",
    "\n",
    "plt.figure(figsize=(6, 7))\n",
    "\n",
    "plt.scatter(r1['r'],\n",
    "            -np.log10(r1['p']),\n",
    "            s=r1['fi']*2000,\n",
    "            color='k',\n",
    "            marker='o',\n",
    "            alpha=0.5)\n",
    "\n",
    "texts = []\n",
    "for t, v in r1[-np.log10(r1['p']) > 2].iterrows():\n",
    "    texts.append(plt.text(v['r'],\n",
    "                          -np.log10(v['p']),\n",
    "                          t,\n",
    "                          ha='center',\n",
    "                          va='center'))\n",
    "adjust_text(texts,\n",
    "            arrowprops=dict(arrowstyle='->', color='k'),\n",
    "            force_points=2)\n",
    "\n",
    "plt.xlabel('pearson\\'s $r$')\n",
    "plt.ylabel('$-log_{10}(pvalue)$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = pd.Series(clf2.feature_importances_,\n",
    "               p['s-scores'].unstack().dropna().T.columns)\n",
    "r1 = r[(r['method'] == 'spearman') &\n",
    "       (r['column'] == 'signed-qvalue')].copy(deep=True)\n",
    "r1['fi'] = [np.nan for x in range(r1.shape[0])]\n",
    "r1 = r1.set_index('condition')\n",
    "r1.loc[fi.index,\n",
    "       'fi'] = fi.values\n",
    "r1 = r1.dropna()\n",
    "\n",
    "plt.figure(figsize=(6, 7))\n",
    "\n",
    "plt.scatter(r1['r'],\n",
    "            -np.log10(r1['p']),\n",
    "            s=r1['fi']*2000,\n",
    "            color='k',\n",
    "            marker='o',\n",
    "            alpha=0.5)\n",
    "\n",
    "texts = []\n",
    "for t, v in r1[-np.log10(r1['p']) > 2].iterrows():\n",
    "    texts.append(plt.text(v['r'],\n",
    "                          -np.log10(v['p']),\n",
    "                          t,\n",
    "                          ha='center',\n",
    "                          va='center'))\n",
    "adjust_text(texts,\n",
    "            arrowprops=dict(arrowstyle='->', color='k'),\n",
    "            force_points=2)\n",
    "\n",
    "plt.xlabel('spearman\\'s $r$')\n",
    "plt.ylabel('$-log_{10}(pvalue)$');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
